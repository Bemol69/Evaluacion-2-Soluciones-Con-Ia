# ü•ä AGENTE INTELIGENTE EVERLAST CHILE
**Evaluaci√≥n Parcial 2 - Desarrollo de Agente Funcional**

---

## üìã INFORMACI√ìN DEL PROYECTO

- **Asignatura**: Inteligencia Artificial
- **M√≥dulo**: IL2 - Sistemas de Agentes Inteligentes
- **Indicadores de Logro**: IL2.1, IL2.2, IL2.3, IL2.4
- **Estudiantes**: Bryan Pi√±a y Juan Castro
- **Fecha**: Octubre 2025
- **Repositorio**: 

---

## üéØ OBJETIVO DEL PROYECTO

Desarrollar un **agente conversacional inteligente** para Everlast Chile que automatice tareas cognitivas complejas en el proceso de atenci√≥n al cliente, espec√≠ficamente:

1. **Consulta de productos**: B√∫squeda sem√°ntica en cat√°logo de equipamiento deportivo
2. **Asesor√≠a t√©cnica**: Recomendaciones de tallas, especificaciones y uso adecuado
3. **C√°lculos comerciales**: Descuentos, conversiones de unidades, totales de compra
4. **Gesti√≥n de pol√≠ticas**: Informaci√≥n sobre env√≠os, devoluciones y garant√≠as

---

## üèóÔ∏è ARQUITECTURA DEL SISTEMA

### Diagrama de Componentes

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        USUARIO FINAL                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ   INTERFAZ DE INTERACCI√ìN     ‚îÇ
         ‚îÇ  ‚Ä¢ CLI (agente_principal.py)  ‚îÇ
         ‚îÇ  ‚Ä¢ Web (app_streamlit.py)     ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    AGENTE PRINCIPAL                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ              CUSTOM LLM (GPT-4o-mini)                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Modelo: gpt-4o-mini via GitHub Models                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Comunicaci√≥n: HTTP directo (requests)                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Prompt Engineering: Sistema + Instrucciones           ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ           SISTEMA DE MEMORIA (IL2.2)                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Short-term: MemoriaSimple (buffer conversacional)     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Contexto: √öltimos 10 mensajes                         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Persistencia: Historial en sesi√≥n activa              ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ      MOTOR DE DECISI√ìN Y PLANIFICACI√ìN (IL2.3)           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ An√°lisis de consulta del usuario                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Selecci√≥n de herramienta apropiada                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Ejecuci√≥n iterativa (m√°x 3 pasos)                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Validaci√≥n y formateo de respuesta                    ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  CAPA DE HERRAMIENTAS (IL2.1)                   ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ BusquedaDocumentosEverlast‚îÇ  ‚îÇ    CalculadoraSimple      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ RAG con FAISS           ‚îÇ  ‚îÇ ‚Ä¢ Operaciones b√°sicas     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Embeddings: text-emb-3  ‚îÇ  ‚îÇ ‚Ä¢ Validaci√≥n de input     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Top-K: 3 chunks         ‚îÇ  ‚îÇ ‚Ä¢ Manejo de errores       ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ
                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              BASE DE CONOCIMIENTO VECTORIAL                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Vector Store FAISS (datos/vectorstore_faiss/)           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ index.faiss: √çndice de 9 vectores (1536 dims)         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ chunks.pkl: Fragmentos de documentos                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ config.pkl: Metadatos del modelo                      ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Documentos Fuente (datos/*.md)                          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ productos.md: Cat√°logo completo                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ tallas.md: Gu√≠a de tallas por peso                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ politicas.md: Env√≠os, devoluciones, garant√≠as        ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîß COMPONENTES PRINCIPALES

### 1. **Agente Principal** (`agente_principal.py`)

**Responsabilidad**: Orquestaci√≥n del flujo conversacional y toma de decisiones.

**Caracter√≠sticas IL2.3 - Planificaci√≥n**:
- **An√°lisis de intenci√≥n**: Interpreta si la consulta requiere herramientas o respuesta directa
- **Planificaci√≥n multi-paso**: Ejecuta hasta 3 iteraciones de razonamiento-acci√≥n-observaci√≥n
- **Adaptaci√≥n din√°mica**: Ajusta estrategia seg√∫n resultados intermedios
- **Manejo de errores**: Recuperaci√≥n ante fallos de herramientas o API

**Flujo de Decisi√≥n**:
```
Usuario ‚Üí LLM (an√°lisis) ‚Üí ¬øNecesita herramienta?
                              ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ                   ‚îÇ
                   S√ç                  NO
                    ‚îÇ                   ‚îÇ
                    ‚ñº                   ‚ñº
           Ejecutar herramienta    Responder
                    ‚îÇ               directamente
                    ‚ñº
           Procesar resultado
                    ‚îÇ
                    ‚ñº
           LLM (respuesta final)
```

**C√≥digo clave**:
```python
class AgenteEverlast:
    def procesar(self, consulta_usuario: str) -> str:
        # 1. Agregar a memoria
        self.memoria.agregar("user", consulta_usuario)
        
        # 2. Preparar contexto con historial
        mensajes = [{"role": "system", "content": self.system_prompt}]
        mensajes.extend(self.memoria.obtener_historial())
        
        # 3. Ciclo de razonamiento (m√°x 3 iteraciones)
        for iteracion in range(3):
            respuesta_llm = self._llamar_llm(mensajes)
            
            # 4. Detectar si necesita herramienta
            if "USAR_HERRAMIENTA:" in respuesta_llm:
                resultado = self._ejecutar_herramienta(...)
                mensajes.append(resultado)
            else:
                break  # Respuesta lista
        
        return respuesta_final
```

---

### 2. **Sistema de Memoria** (IL2.2)

**Implementaci√≥n**: `MemoriaSimple` en `agente_principal.py`

**Tipos de Memoria**:

#### üìù **Short-Term Memory**
- **Prop√≥sito**: Mantener contexto de conversaci√≥n activa
- **Implementaci√≥n**: Buffer circular de √∫ltimos 10 mensajes
- **Persistencia**: Durante sesi√≥n activa
- **Uso**: Responder preguntas de seguimiento, mantener coherencia

```python
class MemoriaSimple:
    def __init__(self):
        self.historial = []
    
    def agregar(self, rol: str, contenido: str):
        self.historial.append({"role": rol, "content": contenido})
    
    def obtener_historial(self, ultimos_n: int = 10):
        return self.historial[-ultimos_n:]  # Ventana deslizante
```

**Ejemplo de uso**:
```
Usuario: "¬øQu√© guantes recomiendas?"
Agente: "Para principiantes recomiendo los Pro Style..."

Usuario: "¬øY en qu√© tallas vienen?" ‚Üê Memoria permite entender "esos" guantes
Agente: "Los Pro Style vienen en 12oz, 14oz y 16oz..."
```

#### üóÑÔ∏è **Long-Term Memory** (Implementaci√≥n mediante Vector Store)
- **Prop√≥sito**: Conocimiento persistente sobre productos/pol√≠ticas
- **Implementaci√≥n**: FAISS con embeddings
- **Recuperaci√≥n**: B√∫squeda sem√°ntica (RAG)
- **Actualizaci√≥n**: Re-indexaci√≥n al modificar documentos fuente

---

### 3. **Herramientas** (`tools_everlast.py`) - IL2.1

#### üîç **BusquedaDocumentosEverlast**

**Tecnolog√≠a**: Retrieval-Augmented Generation (RAG)

**Pipeline**:
```
Query ‚Üí Embedding (text-embedding-3-small) ‚Üí FAISS search ‚Üí Top-3 chunks ‚Üí Contexto
```

**Especificaciones t√©cnicas**:
- **Vector Store**: FAISS IndexFlatL2 (b√∫squeda L2)
- **Dimensi√≥n**: 1536 (text-embedding-3-small)
- **Chunk size**: 1000 caracteres
- **Overlap**: 200 caracteres
- **Top-K**: 3 resultados m√°s relevantes

**C√≥digo**:
```python
def buscar_similares(query: str, k: int = 3) -> List[str]:
    # 1. Generar embedding de query
    query_embedding = obtener_embedding_http(query)
    
    # 2. B√∫squeda en FAISS
    distances, indices = index.search(query_embedding, k)
    
    # 3. Recuperar chunks
    resultados = [chunks[idx].page_content for idx in indices[0]]
    
    return resultados
```

#### üî¢ **CalculadoraSimple**

**Capacidades**:
- Operaciones aritm√©ticas: `+, -, *, /`
- Par√©ntesis para precedencia
- N√∫meros decimales
- Validaci√≥n de seguridad (solo operadores permitidos)

**Casos de uso**:
- C√°lculo de descuentos: `150 * (1 - 0.15)` ‚Üí precio con 15% off
- Conversi√≥n de libras a kg: `16 * 0.453592`
- Totales con IVA: `(100 + 50) * 1.19`

---

### 4. **Generaci√≥n de Vector Store** (`create_vectorstore.py`)

**Proceso de creaci√≥n** (ejecutar una sola vez):

```bash
python codigo/create_vectorstore.py
```

**Pasos internos**:
1. **Carga de documentos**: DirectoryLoader para archivos `.md`
2. **Chunking**: RecursiveCharacterTextSplitter (1000/200)
3. **Embeddings**: HTTP POST a GitHub Models API
4. **Indexaci√≥n**: FAISS IndexFlatL2
5. **Serializaci√≥n**: Pickle para chunks y config

**Archivos generados**:
- `datos/vectorstore_faiss/index.faiss`: √çndice vectorial (54 KB)
- `datos/vectorstore_faiss/chunks.pkl`: Metadatos de chunks (6.8 KB)
- `datos/vectorstore_faiss/config.pkl`: Configuraci√≥n del modelo (0.1 KB)

---

## üöÄ INSTALACI√ìN Y USO

### Requisitos Previos

- Python 3.9+
- Git
- Cuenta GitHub (para GitHub Models API)

### Instalaci√≥n

```bash
# 1. Clonar repositorio
git clone [URL_REPOSITORIO]
cd "Evaluaci√≥n 2"

# 2. Crear entorno virtual
python -m venv venv

# 3. Activar entorno (Windows)
.\venv\Scripts\activate

# 4. Instalar dependencias
pip install -r requirements.txt

# 5. Configurar variables de entorno
# Crear archivo .env con:
GITHUB_TOKEN=tu_token_aqui
OPENAI_BASE_URL=https://models.inference.ai.azure.com
OPENAI_EMBEDDINGS_URL=https://models.github.ai/inference
```

### Configuraci√≥n Inicial

```bash
# Crear vector store (SOLO UNA VEZ)
python codigo/create_vectorstore.py
```

**Salida esperada**:
```
‚úÖ 3 documentos cargados
‚úÖ 9 chunks creados
‚úÖ Embeddings generados: (9, 1536)
‚úÖ √çndice FAISS creado (9 vectores)
‚úÖ Vector store guardado
```

### Ejecuci√≥n

#### Opci√≥n 1: Interfaz de Consola

```bash
python codigo/agente_principal.py
```

**Comandos disponibles**:
- `salir` / `exit`: Terminar sesi√≥n
- `limpiar` / `clear`: Borrar memoria
- `historial`: Ver conversaci√≥n completa

#### Opci√≥n 2: Interfaz Web (Streamlit)

```bash
streamlit run codigo/app_streamlit.py
```

Abre navegador en `http://localhost:8501`

---

## üìä AN√ÅLISIS DEL FLUJO DE TRABAJO

### Proceso Organizacional: Atenci√≥n al Cliente Everlast

**Tareas Cognitivas Identificadas**:

1. **B√∫squeda de informaci√≥n de productos** (Alta complejidad)
   - **Problema**: Cat√°logo de varios productos con especificaciones t√©cnicas
   - **Soluci√≥n**: RAG con b√∫squeda sem√°ntica en documentos internos
   - **Automatizaci√≥n**: Respuestas instant√°neas con contexto relevante

2. **Asesor√≠a personalizada en tallas** (Complejidad media)
   - **Problema**: Tabla de tallas variable seg√∫n peso y tipo de producto
   - **Soluci√≥n**: Recuperaci√≥n de gu√≠a de tallas + razonamiento del LLM
   - **Automatizaci√≥n**: Recomendaciones basadas en perfil del usuario

3. **C√°lculos comerciales** (Baja complejidad)
   - **Problema**: Descuentos, conversiones, totales con impuestos
   - **Soluci√≥n**: Herramienta de calculadora integrada
   - **Automatizaci√≥n**: C√°lculos precisos sin intervenci√≥n humana

4. **Consultas de pol√≠ticas** (Alta repetici√≥n)
   - **Problema**: Mismas preguntas sobre env√≠os/devoluciones
   - **Soluci√≥n**: Base de conocimiento vectorial
   - **Automatizaci√≥n**: 100% de consultas de pol√≠tica automatizables

---

## üéì CUMPLIMIENTO DE INDICADORES DE LOGRO

### ‚úÖ IL2.1: Construcci√≥n de Agente Funcional

**Framework utilizado**: LangChain + Custom LLM

**Herramientas implementadas**:
1. ‚úÖ **Consulta**: `BusquedaDocumentosEverlast` (RAG)
2. ‚úÖ **Razonamiento**: LLM GPT-4o-mini para interpretaci√≥n
3. ‚úÖ **C√°lculo**: `CalculadoraSimple` para operaciones

**Evidencia**:
- Archivo `tools_everlast.py`:  (definici√≥n de herramientas)
- Archivo `agente_principal.py`:  (integraci√≥n de herramientas)

---

### ‚úÖ IL2.2: Sistema de Memoria

**Short-Term Memory**:
- **Implementaci√≥n**: `MemoriaSimple` ( `agente_principal.py`)
- **Capacidad**: 10 mensajes recientes
- **Funci√≥n**: Mantener contexto conversacional

**Long-Term Memory**:
- **Implementaci√≥n**: Vector Store FAISS
- **Persistencia**: Disco (carpeta `datos/vectorstore_faiss/`)
- **Funci√≥n**: Conocimiento persistente de productos/pol√≠ticas

**Recuperaci√≥n de contexto**:
- M√©todo `obtener_historial()`: Recupera ventana de conversaci√≥n
- M√©todo `buscar_similares()`: Recupera conocimiento relevante

**Evidencia**:
- Short-term: `agente_principal.py`, clase `MemoriaSimple`
- Long-term: `create_vectorstore.py`, generaci√≥n de √≠ndice FAISS

---

### ‚úÖ IL2.3: Planificaci√≥n y Toma de Decisiones

**Estrategia implementada**: ReAct simplificado (Reasoning + Acting)

**Componentes**:

1. **An√°lisis de intenci√≥n** :
   ```python
   mensajes = [{"role": "system", "content": self.system_prompt}]
   mensajes.extend(self.memoria.obtener_historial())
   ```

2. **Ciclo de razonamiento iterativo** (l√≠neas 107-135):
   - **Iteraci√≥n 1**: Determina si necesita herramienta
   - **Iteraci√≥n 2-3**: Ejecuta herramienta y procesa resultado
   - **M√°ximo**: 3 iteraciones para evitar loops infinitos

3. **Ajuste din√°mico**:
   - Si "USAR_HERRAMIENTA" detectado ‚Üí ejecuta y reintenta
   - Si "RESPUESTA" directa ‚Üí finaliza y responde
   - Si error ‚Üí manejo de excepciones y mensaje alternativo

**Condiciones cambiantes**:
- Consultas simples (saludo) ‚Üí Respuesta directa sin herramientas
- Consultas de productos ‚Üí Activaci√≥n de RAG
- Consultas con c√°lculos ‚Üí Activaci√≥n de calculadora
- Consultas complejas ‚Üí Combinaci√≥n de herramientas

**Evidencia**: `agente_principal.py`, m√©todo `procesar()` (l√≠neas 89-145)

---

### ‚úÖ IL2.4: Documentaci√≥n T√©cnica

**Este README.md cumple con**:
- ‚úÖ Descripci√≥n completa del dise√±o
- ‚úÖ Diagrama de arquitectura de componentes
- ‚úÖ Explicaci√≥n de orquestaci√≥n entre m√≥dulos
- ‚úÖ Relaci√≥n con flujo automatizado (atenci√≥n al cliente)
- ‚úÖ Instrucciones de instalaci√≥n y uso
- ‚úÖ Evidencia de c√≥digo por indicador de logro

---

## üìÅ ESTRUCTURA DEL PROYECTO

```
Evaluaci√≥n 2/
‚îú‚îÄ‚îÄ codigo/
‚îÇ   ‚îú‚îÄ‚îÄ agente_principal.py       # Agente principal con memoria y planificaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ app_streamlit.py          # Interfaz web interactiva
‚îÇ   ‚îú‚îÄ‚îÄ create_vectorstore.py     # Script de creaci√≥n de √≠ndice FAISS
‚îÇ   ‚îî‚îÄ‚îÄ tools_everlast.py         # Definici√≥n de herramientas (RAG + Calculadora)
‚îÇ
‚îú‚îÄ‚îÄ datos/
‚îÇ   ‚îú‚îÄ‚îÄ productos.md              # Cat√°logo de productos
‚îÇ   ‚îú‚îÄ‚îÄ tallas.md                 # Gu√≠a de tallas
‚îÇ   ‚îú‚îÄ‚îÄ politicas.md              # Pol√≠ticas de env√≠o y devoluci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ vectorstore_faiss/        # √çndice vectorial generado
‚îÇ       ‚îú‚îÄ‚îÄ index.faiss
‚îÇ       ‚îú‚îÄ‚îÄ chunks.pkl
‚îÇ       ‚îî‚îÄ‚îÄ config.pkl
‚îÇ
‚îú‚îÄ‚îÄ documentacion/
‚îÇ   ‚îî‚îÄ‚îÄ README (archivos de referencia)
‚îÇ
‚îú‚îÄ‚îÄ .env                          # Variables de entorno (NO subir a Git)
‚îú‚îÄ‚îÄ .gitignore                    # Exclusiones de Git
‚îú‚îÄ‚îÄ requirements.txt              # Dependencias del proyecto
‚îú‚îÄ‚îÄ Pasos.txt                     # Gu√≠a r√°pida de ejecuci√≥n
‚îî‚îÄ‚îÄ README.md                     # Este archivo
```

---

## üß™ PRUEBAS Y VALIDACI√ìN

### Casos de Prueba

#### Test 1: Consulta de producto
```
Usuario: "¬øQu√© guantes recomiendas para sparring?"
Esperado: Activaci√≥n de BusquedaDocumentosEverlast + recomendaci√≥n de 14oz o 16oz
```

#### Test 2: Memoria conversacional
```
Usuario: "Hola"
Agente: "¬°Hola! ¬øC√≥mo puedo ayudarte?"
Usuario: "¬øCu√°nto cuesta un saco de boxeo?"
Agente: [Busca en documentos]
Usuario: "¬øY viene con cadena?"  ‚Üê Requiere recordar "saco de boxeo"
Esperado: Respuesta contextual sin re-preguntar qu√© producto
```

#### Test 3: C√°lculo de descuento
```
Usuario: "Si un guante cuesta $45.990 y tiene 20% de descuento, ¬øcu√°nto pagar√≠a?"
Esperado: Uso de CalculadoraSimple ‚Üí "45990 * (1 - 0.20)" = $36.792
```

#### Test 4: Comando de limpieza
```
Usuario: "limpiar"
Esperado: Memoria borrada, siguiente consulta no tiene contexto previo
```

### Ejecuci√≥n de Tests

```bash
# Probar herramientas standalone
python codigo/tools_everlast.py

# Salida esperada:
# ‚úÖ 3 fragmentos recuperados (RAG)
# ‚úÖ Calculadora: 127.5, 178.5, 7.257472
```

---

## üõ†Ô∏è TECNOLOG√çAS UTILIZADAS

| Componente | Tecnolog√≠a | Versi√≥n |
|------------|-----------|---------|
| Lenguaje | Python | 3.9+ |
| Framework Agentes | LangChain | 0.1.20 |
| LLM | GPT-4o-mini | GitHub Models |
| Embeddings | text-embedding-3-small | GitHub Models |
| Vector Store | FAISS | 1.8.0 |
| Web Framework | Streamlit | 1.32.0 |
| HTTP Client | Requests | 2.31.0 |
| Gesti√≥n de Env | python-dotenv | 1.0.1 |

---

## ‚ö†Ô∏è LIMITACIONES CONOCIDAS

1. **Memoria long-term**: No hay persistencia entre sesiones (se pierde al cerrar)
2. **Escalabilidad**: FAISS IndexFlatL2 no es √≥ptimo para >100K vectores
3. **Multilenguaje**: Solo espa√±ol, sin soporte para otros idiomas
4. **Validaci√≥n de entrada**: Calculadora no detecta expresiones maliciosas complejas

---

## üöÄ MEJORAS FUTURAS

1. **Memoria persistente**: Integrar SQLite o Redis para historial multi-sesi√≥n
2. **Planificaci√≥n avanzada**: Implementar algoritmo MCTS o A* para tareas complejas
3. **Herramientas adicionales**: 
   - Consulta de stock en tiempo real (API)
   - Generaci√≥n de cotizaciones en PDF
   - Integraci√≥n con sistema de tickets
4. **Evaluaci√≥n de calidad**: M√©tricas de satisfacci√≥n del usuario

---

## üë• AUTORES

- **Bryan Pi√±a** - Desarrollo de agente y herramientas
- **Juan Castro** - Sistema de memoria y vector store

---

## üìÑ LICENCIA

Este proyecto es parte de una evaluaci√≥n acad√©mica.  
Instituci√≥n: Duoc Uc  
Asignatura: Doluciones con Inteligencia Artificial 

---

**Versi√≥n**: 1.0.0